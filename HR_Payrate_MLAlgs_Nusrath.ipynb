{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from datetime import datetime\n",
    "\n",
    "class HR_Data_Prep_Utility(object):\n",
    "\t\"\"\"HR_Data_Prep_Utility is used for preparing data for the ML\"\"\"\n",
    "\n",
    "\tdef __init__(self, dataset, feature_col, target_col):\n",
    "\t\t\"\"\"\n",
    "\t\tInitialize and builds the HR Dataset to be used in training a model\n",
    "\t\t\n",
    "\t\tOnly the below features are supported\n",
    "\t\t['MarriedID', 'MaritalStatusID', 'GenderID', 'EmpStatusID', 'DeptID', 'PerfScoreID', 'PayRate', 'Termd', 'PositionID', 'State', 'DOB', 'CitizenDesc', 'HispanicLatino', 'RaceDesc', 'DateofHire', 'DateofTermination', 'ManagerName', 'RecruitmentSource', 'EngagementSurvey', 'EmpSatisfaction', 'SpecialProjectsCount', 'LastPerformanceReview_Date']\n",
    "\n",
    "\t\t:param dataset: pandas dataframe read from csv\n",
    "\t\t:param feature_col: column names of the features\n",
    "\t\t:param target_col: column name of the target\n",
    "\t\t\"\"\"\n",
    "\t\tsuper(HR_Data_Prep_Utility, self).__init__()\n",
    "\t\tself.emp_ds = dataset\n",
    "\t\tself.feature_col = feature_col\n",
    "\t\tself.target_col = target_col\n",
    "\t\tself._cat_col = ['MarriedID', 'MaritalStatusID', 'GenderID','EmpStatusID', 'DeptID', 'Termd', 'PositionID','State', 'CitizenDesc', 'HispanicLatino', 'RaceDesc', 'ManagerName', 'RecruitmentSource']\n",
    "\t\tself._num_col = ['PayRate', 'PerfScoreID', 'Age', 'CurrentCmpyExp', 'EngagementSurvey', 'EmpSatisfaction','SpecialProjectsCount', 'DaysSinceLastRev']\n",
    "\t\tself._cat_col_onehot = ['MarriedID', 'MaritalStatusID', 'GenderID','EmpStatusID', 'Termd', 'CitizenDesc', 'HispanicLatino']\n",
    "\t\tself._cat_columns_feat_hash = ['DeptID', 'PositionID','State', 'RaceDesc', 'ManagerName', 'RecruitmentSource']\n",
    "\n",
    "\n",
    "\tdef get_x_y_data(self):\n",
    "\t\t\"\"\"\n",
    "\t\tDescription\n",
    "\t\t:param name: description\n",
    "\t\t:return: Description\n",
    "\t\t\"\"\"\n",
    "\t\tX, y = self._split_x_y(self.emp_ds)\n",
    "\t\tX = self._add_features(X[self.feature_col])\n",
    "\t\tX = self._missing_value_fix(X)\n",
    "\t\tX = self._encode_category_features(X, reduction_ratio=0.5)\n",
    "\t\ty = self._missing_value_fix(y)\n",
    "\t\ty = self._encode_category_features(y, reduction_ratio=0.5)\n",
    "\t\tX = self._scale_data(X)\n",
    "\t\treturn X, y\n",
    "\n",
    "\n",
    "\tdef _fe_fill_missing_val(self, X, column_name, fe_type):\n",
    "\t\t\"\"\"\n",
    "\t\tDescription\n",
    "\t\t:param name: description\n",
    "\t\t:return: Description\n",
    "\t\t\"\"\"\n",
    "\t\tif(fe_type is 'num'):\n",
    "\t\t\tX[column_name + '_missing'] =  np.zeros((len(X.index), 1))\n",
    "\t\t\tX.iloc[(X.loc[X[column_name].isna() == True]).index, X.columns.get_loc(column_name + '_missing')] = 1\n",
    "\t\t\tX.iloc[(X.loc[X[column_name].isna() == True]).index, X.columns.get_loc(column_name)] = 0\n",
    "\t\telif(fe_type is 'str'):\n",
    "\t\t\tX.iloc[(X.loc[X[column_name].isna() == True]).index, X.columns.get_loc(column_name)] = 'Missing'\n",
    "\t\treturn X\n",
    "\n",
    "\n",
    "\tdef _fe_category_feature_hashing(self, X, column_name, n_features):\n",
    "\t\t\"\"\"\n",
    "\t\tDescription\n",
    "\t\t:param name: description\n",
    "\t\t:return: Description\n",
    "\t\t\"\"\"\n",
    "\t\tfh = FeatureHasher(n_features=n_features, input_type='string')\n",
    "\t\tx_features_arr = fh.fit_transform(X[column_name].astype('str')).toarray()\n",
    "\t\tcolumn_names = np.array([])\n",
    "\t\tfor i in range(n_features):\n",
    "\t\t\tcolumn_names = np.append(column_names, column_name+'_'+str(i+1))\n",
    "\t\treturn pd.concat([X, pd.DataFrame(x_features_arr, columns=column_names)], axis=1)\n",
    "\n",
    "\n",
    "\tdef _fe_category_one_hot_encoder(self, X, column_name):\n",
    "\t\t\"\"\"\n",
    "\t\tDescription\n",
    "\t\t:param name: description\n",
    "\t\t:return: Description\n",
    "\t\t\"\"\"\n",
    "\t\tx_features_arr = pd.get_dummies(X[column_name])\n",
    "\t\tx_features_arr.rename(columns=lambda x: column_name+'_' + str(x), inplace=True)\n",
    "\t\treturn pd.concat([X, x_features_arr], axis=1)\n",
    "\n",
    "\n",
    "\tdef _split_x_y(self, X):\n",
    "\t\t\"\"\"\n",
    "\t\tDescription\n",
    "\t\t:param name: description\n",
    "\t\t:return: Description\n",
    "\t\t\"\"\"\n",
    "\t\treturn X[self.feature_col], X[self.target_col]\n",
    "\n",
    "\n",
    "\tdef _add_features(self, X):\n",
    "\t\t\"\"\"\n",
    "\t\tDescription\n",
    "\t\t:param name: description\n",
    "\t\t:return: Description\n",
    "\t\t\"\"\"\n",
    "\t\tnow = datetime.now()\n",
    "\t\tif set(['DateofHire','DateofTermination', 'Termd']).issubset(X.columns):\n",
    "\t\t\tX['DateofHire'] = pd.to_datetime(X['DateofHire'], format=\"%m/%d/%Y\")\n",
    "\t\t\tX['DateofTermination'] = pd.to_datetime(X['DateofTermination'], format=\"%m/%d/%y\")\n",
    "\t\t\tX.loc[X['Termd'] == 0, 'CurrentCmpyExp'] = X['DateofHire'].apply(lambda x: now.year - x.year)\n",
    "\t\t\tX.loc[X['Termd'] == 1, 'CurrentCmpyExp'] = (X['DateofTermination'] - X['DateofHire'])/np.timedelta64(1,'Y')\n",
    "\t\t\tX = X.drop(['DateofHire', 'DateofTermination'], axis=1)\n",
    "\t\tif 'LastPerformanceReview_Date' in X.columns:\n",
    "\t\t\tX['LastPerformanceReview_Date'] = pd.to_datetime(X['LastPerformanceReview_Date'], format=\"%m/%d/%Y\")\n",
    "\t\t\tX['DaysSinceLastRev'] = X['LastPerformanceReview_Date'].apply(lambda x: (now - x).days)\n",
    "\t\t\tX = X.drop(['LastPerformanceReview_Date'], axis=1)\n",
    "\t\tif 'DOB' in X.columns:\n",
    "\t\t\tX['DOB'] = pd.to_datetime(X['DOB'], format=\"%d-%m-%Y\")\n",
    "\t\t\tX['Age'] = X['DOB'].apply(lambda x: now.year - x.year)\n",
    "\t\t\tX = X.drop(['DOB'], axis=1)\n",
    "\t\treturn X\n",
    "\n",
    "\n",
    "\tdef _format_date_of_termination(self, X):\n",
    "\t\t\"\"\"\n",
    "\t\tDescription\n",
    "\t\t:param name: description\n",
    "\t\t:return: Description\n",
    "\t\t\"\"\"\n",
    "\t\tpattern1_match = X['DateofTermination'].str.match(pat = '^(0[1-9]|1[012])/(0[1-9]|1[0-9]|2[0-9]|3[01])/([0-9]{2})$')\n",
    "\t\tdates_p1 = pd.to_datetime((X[pattern1_match==True])['DateofTermination'], format=\"%m/%d/%y\")\n",
    "\t\tpattern2_match = X['DateofTermination'].str.match(pat = '^((19|2[0-9])[0-9]{2})/(0[1-9]|1[012])/(0[1-9]|[12][0-9]|3[01])$')\n",
    "\t\tdates_p2 = pd.to_datetime((X[pattern2_match==True])['DateofTermination'], format=\"%Y/%m/%d\")\n",
    "\t\tcombined_dates = dates_p1.append(dates_p2)\n",
    "\t\tX = X.drop(['DateofTermination'], axis=1)\n",
    "\t\tX.at[combined_dates.index, 'DateofTermination'] = combined_dates.values\n",
    "\t\treturn X\n",
    "\n",
    "\n",
    "\tdef _missing_value_fix(self, X):\n",
    "\t\t\"\"\"\n",
    "\t\tDescription\n",
    "\t\t:param name: description\n",
    "\t\t:return: Description\n",
    "\t\t\"\"\"\n",
    "\t\t#Added features are missed from this.. \n",
    "\t\tcat_columns = list(set(self.feature_col) & set(self._cat_col))\n",
    "\t\tnum_columns = list(set(self.feature_col) & set(self._num_col)) + ['CurrentCmpyExp', 'DaysSinceLastRev', 'Age']\n",
    "\t\tfor column in cat_columns:\n",
    "\t\t\tif column in X.columns:\n",
    "\t\t\t\tX = self._fe_fill_missing_val(X, column, 'str')\n",
    "\t\tfor column in num_columns:\n",
    "\t\t\tif column in X.columns:\n",
    "\t\t\t\tX = self._fe_fill_missing_val(X, column, 'num')\n",
    "\t\treturn X\n",
    "\n",
    "\n",
    "\tdef _encode_category_features(self, X, reduction_ratio):\n",
    "\t\t\"\"\"\n",
    "\t\tDescription\n",
    "\t\t:param name: description\n",
    "\t\t:return: Description\n",
    "\t\t\"\"\"\n",
    "\t\tcat_columns_oh = list(set(self.feature_col) & set(self._cat_col_onehot))\n",
    "\t\tcat_columns_fh = list(set(self.feature_col) & set(self._cat_columns_feat_hash))\n",
    "\t\tfor column in cat_columns_oh:\n",
    "\t\t\tif column in X.columns:\n",
    "\t\t\t\tX = self._fe_category_one_hot_encoder(X, column)\n",
    "\t\tfor column in cat_columns_fh:\n",
    "\t\t\tif column in X.columns:\n",
    "\t\t\t\tX = self._fe_category_feature_hashing(X, column, int(len(X[column].unique())*reduction_ratio))\n",
    "\t\tdrop_encoded_fe = []\n",
    "\t\tfor column in cat_columns_oh + cat_columns_fh:\n",
    "\t\t\tif column in X.columns:\n",
    "\t\t\t\tdrop_encoded_fe.append(column)\n",
    "\t\tX = X.drop(drop_encoded_fe, axis=1)\n",
    "\t\treturn X\n",
    "\n",
    "\n",
    "\tdef _scale_data(self, X):\n",
    "\t\t\"\"\"\n",
    "\t\tDescription\n",
    "\t\t:param name: description\n",
    "\t\t:return: Description\n",
    "\t\t\"\"\"\n",
    "\t\tscaler = StandardScaler()\n",
    "\t\tscaler.fit(X)\n",
    "\t\treturn pd.DataFrame(scaler.transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import r2_score, mean_absolute_error,explained_variance_score\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression, RANSACRegressor, Lasso, Ridge\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_ds_l = pd.read_csv('../HRDataset_v13_Working_BU.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_features = ['MarriedID', 'MaritalStatusID', 'GenderID', 'EmpStatusID', 'DeptID', 'PerfScoreID', 'Termd', 'PositionID', 'State', 'DOB','DateofHire', 'DateofTermination', 'ManagerName', 'RecruitmentSource', 'EngagementSurvey', 'EmpSatisfaction', 'SpecialProjectsCount', 'LastPerformanceReview_Date']\n",
    "y_features = ['PayRate']\n",
    "hr_prep = HR_Data_Prep_Utility(emp_ds_l, x_features, y_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X, y = hr_prep.get_x_y_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)\n",
      "\tTraining time: 0.005s)\n",
      "\tPrediction time: 0.001s\n",
      "\tExplained variance: 0.26022561772427943\n",
      "\tMean absolute error: 7.39591176884318\n",
      "\tR2 score: 0.23956791716551362\n",
      "RANSACRegressor(base_estimator=None, is_data_valid=None, is_model_valid=None,\n",
      "                loss='absolute_loss', max_skips=inf, max_trials=100,\n",
      "                min_samples=None, random_state=None, residual_threshold=None,\n",
      "                stop_n_inliers=inf, stop_probability=0.99, stop_score=inf)\n",
      "\tTraining time: 0.139s)\n",
      "\tPrediction time: 0.001s\n",
      "\tExplained variance: -3.630387620826281e+25\n",
      "\tMean absolute error: 17849089092167.613\n",
      "\tR2 score: -3.7514005415204786e+25\n",
      "LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_intercept=True,\n",
      "          intercept_scaling=1.0, loss='epsilon_insensitive', max_iter=1000,\n",
      "          random_state=None, tol=0.0001, verbose=0)\n",
      "\tTraining time: 0.009s)\n",
      "\tPrediction time: 0.001s\n",
      "\tExplained variance: 0.6661764527497256\n",
      "\tMean absolute error: 5.855450930327271\n",
      "\tR2 score: 0.6660436745587146\n",
      "GaussianProcessRegressor(alpha=1e-10, copy_X_train=True, kernel=None,\n",
      "                         n_restarts_optimizer=0, normalize_y=False,\n",
      "                         optimizer='fmin_l_bfgs_b', random_state=None)\n",
      "\tTraining time: 0.007s)\n",
      "\tPrediction time: 0.001s\n",
      "\tExplained variance: 0.020861244686375957\n",
      "\tMean absolute error: 32.504487100323765\n",
      "\tR2 score: -3.9922968013579982\n",
      "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=None,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False)\n",
      "\tTraining time: 0.002s)\n",
      "\tPrediction time: 0.000s\n",
      "\tExplained variance: 0.7640087774619461\n",
      "\tMean absolute error: 5.086114192057681\n",
      "\tR2 score: 0.763137512427902\n",
      "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "      normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "\tTraining time: 0.001s)\n",
      "\tPrediction time: 0.000s\n",
      "\tExplained variance: 0.3748132522043842\n",
      "\tMean absolute error: 7.2609748024599385\n",
      "\tR2 score: 0.3571439832814225\n"
     ]
    }
   ],
   "source": [
    "regressors = [\n",
    "    LinearRegression(), \n",
    "    RANSACRegressor(), \n",
    "    LinearSVR(),\n",
    "    GaussianProcessRegressor(),\n",
    "    Lasso(),\n",
    "    Ridge() \n",
    "]\n",
    "\n",
    "for model in regressors:\n",
    "    start = time()\n",
    "    model.fit(X_train, y_train.values.ravel())\n",
    "    train_time = time() - start\n",
    "    start = time()\n",
    "    predictions = model.predict(X_test)\n",
    "    predict_time = time()-start    \n",
    "    print(model)\n",
    "    print(\"\\tTraining time: %0.3fs)\" % train_time)\n",
    "    print(\"\\tPrediction time: %0.3fs\" % predict_time)\n",
    "    print(\"\\tExplained variance:\", explained_variance_score(y_test, predictions))\n",
    "    print(\"\\tMean absolute error:\", mean_absolute_error(y_test, predictions))\n",
    "    print(\"\\tR2 score:\", r2_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                    weights='uniform')\n",
      "\tTraining time: 0.001s)\n",
      "\tPrediction time: 0.003s\n",
      "\tExplained variance: 0.6527740958219195\n",
      "\tMean absolute error: 6.603354838709678\n",
      "\tR2 score: 0.6142587553449956\n",
      "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n",
      "    gamma='auto_deprecated', kernel='rbf', max_iter=-1, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "\tTraining time: 0.009s)\n",
      "\tPrediction time: 0.002s\n",
      "\tExplained variance: 0.3616607501410811\n",
      "\tMean absolute error: 9.81468801769497\n",
      "\tR2 score: 0.21795902624397268\n",
      "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n",
      "    gamma='auto_deprecated', kernel='linear', max_iter=-1, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "\tTraining time: 0.024s)\n",
      "\tPrediction time: 0.002s\n",
      "\tExplained variance: 0.6755697129860347\n",
      "\tMean absolute error: 5.819081065698808\n",
      "\tR2 score: 0.6738653166968672\n",
      "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
      "                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      presort=False, random_state=None, splitter='best')\n",
      "\tTraining time: 0.003s)\n",
      "\tPrediction time: 0.000s\n",
      "\tExplained variance: 0.6178880767428143\n",
      "\tMean absolute error: 5.630967741935483\n",
      "\tR2 score: 0.6173321140897232\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "                      n_jobs=None, oob_score=False, random_state=None,\n",
      "                      verbose=0, warm_start=False)\n",
      "\tTraining time: 0.020s)\n",
      "\tPrediction time: 0.001s\n",
      "\tExplained variance: 0.8471274966944278\n",
      "\tMean absolute error: 4.248322580645161\n",
      "\tR2 score: 0.8408299663531678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\narif\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\narif\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "regressors = [\n",
    "    KNeighborsRegressor(),\n",
    "    SVR(),\n",
    "    SVR(kernel = 'linear'),\n",
    "    DecisionTreeRegressor(),\n",
    "    RandomForestRegressor()\n",
    "              ]\n",
    "\n",
    "for model in regressors:\n",
    "    start = time()\n",
    "    model.fit(X_train, y_train.values.ravel())\n",
    "    train_time = time() - start\n",
    "    start = time()\n",
    "    predictions = model.predict(X_test)\n",
    "    predict_time = time()-start  \n",
    "    print(model)\n",
    "    print(\"\\tTraining time: %0.3fs)\" % train_time)\n",
    "    print(\"\\tPrediction time: %0.3fs\" % predict_time)\n",
    "    print(\"\\tExplained variance:\", explained_variance_score(y_test, predictions))\n",
    "    print(\"\\tMean absolute error:\", mean_absolute_error(y_test, predictions))\n",
    "    print(\"\\tR2 score:\", r2_score(y_test, predictions))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

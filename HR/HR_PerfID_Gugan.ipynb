{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Paste the class file here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from datetime import datetime\n",
    "\n",
    "class HR_Data_Prep_Utility(object):\n",
    "\t\"\"\"HR_Data_Prep_Utility is used for preparing data for the ML\"\"\"\n",
    "\n",
    "\tdef __init__(self, dataset, feature_col, target_col, fe_hashing_ratio):\n",
    "\t\t\"\"\"\n",
    "\t\tInitialize and builds the HR Dataset to be used in training a model\n",
    "\t\t\n",
    "\t\tOnly the below features are supported\n",
    "\t\t['MarriedID', 'MaritalStatusID', 'GenderID', 'EmpStatusID', 'DeptID', 'PerfScoreID', 'PayRate', 'Termd', 'PositionID', 'State', 'DOB', 'CitizenDesc', 'HispanicLatino', 'RaceDesc', 'DateofHire', 'DateofTermination', 'ManagerName', 'RecruitmentSource', 'EngagementSurvey', 'EmpSatisfaction', 'SpecialProjectsCount', 'LastPerformanceReview_Date']\n",
    "\n",
    "\t\t:param dataset: pandas dataframe read from csv\n",
    "\t\t:param feature_col: column names of the features\n",
    "\t\t:param target_col: column name of the target\n",
    "\t\t\"\"\"\n",
    "\t\tsuper(HR_Data_Prep_Utility, self).__init__()\n",
    "\t\tself.emp_ds = dataset\n",
    "\t\tself.feature_col = feature_col\n",
    "\t\tself.target_col = target_col\n",
    "\t\tself.fe_hashing_ratio = fe_hashing_ratio\n",
    "\t\tself._cat_col = ['MarriedID', 'MaritalStatusID', 'GenderID','EmpStatusID', 'DeptID', 'Termd', 'PositionID','State', 'CitizenDesc', 'HispanicLatino', 'RaceDesc', 'ManagerName', 'RecruitmentSource']\n",
    "\t\tself._num_col = ['PayRate', 'PerfScoreID', 'Age', 'CurrentCmpyExp', 'EngagementSurvey', 'EmpSatisfaction','SpecialProjectsCount', 'DaysSinceLastRev']\n",
    "\t\tself._cat_col_onehot = ['MarriedID', 'MaritalStatusID', 'GenderID','EmpStatusID', 'Termd', 'CitizenDesc', 'HispanicLatino']\n",
    "\t\tself._cat_columns_feat_hash = ['DeptID', 'PositionID','State', 'RaceDesc', 'ManagerName', 'RecruitmentSource']\n",
    "\n",
    "\n",
    "\tdef get_x_y_data(self):\n",
    "\t\t\"\"\"\n",
    "\t\tDescription\n",
    "\t\t:param name: description\n",
    "\t\t:return: Description\n",
    "\t\t\"\"\"\n",
    "\t\tX, y = self._split_x_y(self.emp_ds)\n",
    "\t\tX = self._values_fix(X)\n",
    "\t\tX = self._add_features(X[self.feature_col])\n",
    "\t\tX = self._missing_values_fix(X)\n",
    "\t\tX = self._encode_category_features(X, reduction_ratio=self.fe_hashing_ratio)\n",
    "\t\ty = self._missing_values_fix(y)\n",
    "\t\ty = self._encode_category_features(y, reduction_ratio=self.fe_hashing_ratio)\n",
    "\t\tX = self._scale_data(X)\n",
    "\t\treturn X, y\n",
    "\n",
    "\n",
    "\tdef _fe_fill_missing_val(self, X, column_name, fe_type):\n",
    "\t\t\"\"\"\n",
    "\t\tDescription\n",
    "\t\t:param name: description\n",
    "\t\t:return: Description\n",
    "\t\t\"\"\"\n",
    "\t\tif(fe_type is 'num'):\n",
    "\t\t\tX[column_name + '_missing'] =  np.zeros((len(X.index), 1))\n",
    "\t\t\t#X.iloc[(X.loc[X[column_name].isna() == True]).index, X.columns.get_loc(column_name + '_missing')] = 1\n",
    "\t\t\tX.loc[X[column_name].isna() == True, column_name + '_missing'] = 1\n",
    "\t\t\t#X.iloc[(X.loc[X[column_name].isna() == True]).index, X.columns.get_loc(column_name)] = 0\n",
    "\t\t\tX.loc[X[column_name].isna() == True, column_name] = 0\n",
    "\t\telif(fe_type is 'str'):\n",
    "\t\t\t#X.iloc[(X.loc[X[column_name].isna() == True]).index, X.columns.get_loc(column_name)] = 'Missing'\n",
    "\t\t\tX.loc[X[column_name].isna() == True, column_name] = 'Missing'\n",
    "\t\treturn X\n",
    "\n",
    "\n",
    "\tdef _fe_category_feature_hashing(self, X, column_name, n_features):\n",
    "\t\t\"\"\"\n",
    "\t\tDescription\n",
    "\t\t:param name: description\n",
    "\t\t:return: Description\n",
    "\t\t\"\"\"\n",
    "\t\tfh = FeatureHasher(n_features=n_features, input_type='string')\n",
    "\t\tx_features_arr = fh.fit_transform(X[column_name].astype('str')).toarray()\n",
    "\t\tcolumn_names = np.array([])\n",
    "\t\tfor i in range(n_features):\n",
    "\t\t\tcolumn_names = np.append(column_names, column_name+'_'+str(i+1))\n",
    "\t\treturn pd.concat([X, pd.DataFrame(x_features_arr, columns=column_names)], axis=1)\n",
    "\n",
    "\n",
    "\tdef _fe_category_one_hot_encoder(self, X, column_name):\n",
    "\t\t\"\"\"\n",
    "\t\tDescription\n",
    "\t\t:param name: description\n",
    "\t\t:return: Description\n",
    "\t\t\"\"\"\n",
    "\t\tx_features_arr = pd.get_dummies(X[column_name])\n",
    "\t\tx_features_arr.rename(columns=lambda x: column_name+'_' + str(x), inplace=True)\n",
    "\t\treturn pd.concat([X, x_features_arr], axis=1)\n",
    "\n",
    "\n",
    "\tdef _split_x_y(self, X):\n",
    "\t\t\"\"\"\n",
    "\t\tDescription\n",
    "\t\t:param name: description\n",
    "\t\t:return: Description\n",
    "\t\t\"\"\"\n",
    "\t\treturn X[self.feature_col], X[self.target_col]\n",
    "\n",
    "\n",
    "\tdef _add_features(self, X):\n",
    "\t\t\"\"\"\n",
    "\t\tDescription\n",
    "\t\t:param name: description\n",
    "\t\t:return: Description\n",
    "\t\t\"\"\"\n",
    "\t\tnow = datetime.now()\n",
    "\t\tif set(['DateofHire','DateofTermination', 'Termd']).issubset(X.columns):\n",
    "\t\t\tX['DateofHire'] = pd.to_datetime(X['DateofHire'], format=\"%m/%d/%Y\")\n",
    "\t\t\tX['DateofTermination'] = pd.to_datetime(X['DateofTermination'], format=\"%m/%d/%y\")\n",
    "\t\t\tX.loc[X['Termd'] == 0, 'CurrentCmpyExp'] = X['DateofHire'].apply(lambda x: now.year - x.year)\n",
    "\t\t\tX.loc[X['Termd'] == 1, 'CurrentCmpyExp'] = (X['DateofTermination'] - X['DateofHire'])/np.timedelta64(1,'Y')\n",
    "\t\t\tX = X.drop(['DateofHire', 'DateofTermination'], axis=1)\n",
    "\t\tif 'LastPerformanceReview_Date' in X.columns:\n",
    "\t\t\tX['LastPerformanceReview_Date'] = pd.to_datetime(X['LastPerformanceReview_Date'], format=\"%m/%d/%Y\")\n",
    "\t\t\tX['DaysSinceLastRev'] = X['LastPerformanceReview_Date'].apply(lambda x: (now - x).days)\n",
    "\t\t\tX = X.drop(['LastPerformanceReview_Date'], axis=1)\n",
    "\t\tif 'DOB' in X.columns:\n",
    "\t\t\tX['DOB'] = pd.to_datetime(X['DOB'], format=\"%d-%m-%Y\")\n",
    "\t\t\tX['Age'] = X['DOB'].apply(lambda x: now.year - x.year)\n",
    "\t\t\tX = X.drop(['DOB'], axis=1)\n",
    "\t\treturn X\n",
    "\n",
    "\n",
    "\tdef _format_date_of_termination(self, X):\n",
    "\t\t\"\"\"\n",
    "\t\tDescription\n",
    "\t\t:param name: description\n",
    "\t\t:return: Description\n",
    "\t\t\"\"\"\n",
    "\t\tpattern1_match = X['DateofTermination'].str.match(pat = '^(0[1-9]|1[012])/(0[1-9]|1[0-9]|2[0-9]|3[01])/([0-9]{2})$')\n",
    "\t\tdates_p1 = pd.to_datetime((X[pattern1_match==True])['DateofTermination'], format=\"%m/%d/%y\")\n",
    "\t\tpattern2_match = X['DateofTermination'].str.match(pat = '^((19|2[0-9])[0-9]{2})/(0[1-9]|1[012])/(0[1-9]|[12][0-9]|3[01])$')\n",
    "\t\tdates_p2 = pd.to_datetime((X[pattern2_match==True])['DateofTermination'], format=\"%Y/%m/%d\")\n",
    "\t\tcombined_dates = dates_p1.append(dates_p2)\n",
    "\t\tX = X.drop(['DateofTermination'], axis=1)\n",
    "\t\tX.at[combined_dates.index, 'DateofTermination'] = combined_dates.values\n",
    "\t\treturn X\n",
    "\n",
    "\n",
    "\tdef _missing_values_fix(self, X):\n",
    "\t\t\"\"\"\n",
    "\t\tDescription\n",
    "\t\t:param name: description\n",
    "\t\t:return: Description\n",
    "\t\t\"\"\"\n",
    "\t\t#Added features are missed from this.. \n",
    "\t\tcat_columns = list(set(self.feature_col) & set(self._cat_col))\n",
    "\t\tnum_columns = list(set(self.feature_col) & set(self._num_col)) + ['CurrentCmpyExp', 'DaysSinceLastRev', 'Age']\n",
    "\t\tfor column in cat_columns:\n",
    "\t\t\tif column in X.columns:\n",
    "\t\t\t\tX = self._fe_fill_missing_val(X, column, 'str')\n",
    "\t\tfor column in num_columns:\n",
    "\t\t\tif column in X.columns:\n",
    "\t\t\t\tX = self._fe_fill_missing_val(X, column, 'num')\n",
    "\t\treturn X\n",
    "\n",
    "\n",
    "\tdef _values_fix(self, X):\n",
    "\t\t\"\"\"\n",
    "\t\tDescription\n",
    "\t\t:param name: description\n",
    "\t\t:return: Description\n",
    "\t\t\"\"\"\n",
    "\t\tif 'HispanicLatino' in X.columns:\n",
    "\t\t\tX.loc[X['HispanicLatino']=='yes', 'HispanicLatino'] = 'Yes'\n",
    "\t\t\tX.loc[X['HispanicLatino']=='no', 'HispanicLatino'] = 'No'\n",
    "\t\treturn X\n",
    "\n",
    "\n",
    "\tdef _encode_category_features(self, X, reduction_ratio):\n",
    "\t\t\"\"\"\n",
    "\t\tDescription\n",
    "\t\t:param name: description\n",
    "\t\t:return: Description\n",
    "\t\t\"\"\"\n",
    "\t\tcat_columns_oh = list(set(self.feature_col) & set(self._cat_col_onehot))\n",
    "\t\tcat_columns_fh = list(set(self.feature_col) & set(self._cat_columns_feat_hash))\n",
    "\t\tfor column in cat_columns_oh:\n",
    "\t\t\tif column in X.columns:\n",
    "\t\t\t\tX = self._fe_category_one_hot_encoder(X, column)\n",
    "\t\tfor column in cat_columns_fh:\n",
    "\t\t\tif column in X.columns:\n",
    "\t\t\t\t#X = self._fe_category_feature_hashing(X, column, int(len(X[column].unique())*reduction_ratio))\n",
    "\t\t\t\tX = self._fe_category_one_hot_encoder(X, column)\n",
    "\t\tdrop_encoded_fe = []\n",
    "\t\tfor column in cat_columns_oh + cat_columns_fh:\n",
    "\t\t\tif column in X.columns:\n",
    "\t\t\t\tdrop_encoded_fe.append(column)\n",
    "\t\tX = X.drop(drop_encoded_fe, axis=1)\n",
    "\t\treturn X\n",
    "\n",
    "\n",
    "\tdef _scale_data(self, X):\n",
    "\t\t\"\"\"\n",
    "\t\tDescription\n",
    "\t\t:param name: description\n",
    "\t\t:return: Description\n",
    "\t\t\"\"\"\n",
    "\t\tscaler = StandardScaler()\n",
    "\t\tscaler.fit(X)\n",
    "\t\treturn pd.DataFrame(scaler.transform(X), columns=X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the csv file.. \n",
    "if it is in local, follow below, if it is google colab, follow 2nd method given by Nusrath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_ds_l = pd.read_csv('HRDataset_v13.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare two lists\n",
    "One - which columns are going to be your X features\n",
    "two - which columns are going to be your y feaute (only one)\n",
    "Create a object for the class intializing these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_features = ['MarriedID', 'MaritalStatusID', 'GenderID','EmpStatusID', 'DeptID', 'PayRate', 'Termd', 'PositionID','State', 'DOB', 'CitizenDesc', 'HispanicLatino', 'RaceDesc', 'DateofHire', 'DateofTermination','ManagerName', 'RecruitmentSource', 'EngagementSurvey', 'EmpSatisfaction','SpecialProjectsCount', 'LastPerformanceReview_Date']\n",
    "y_features = ['PerfScoreID']\n",
    "hr_prep = HR_Data_Prep_Utility(emp_ds_l, x_features, y_features, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call get_x_y_data method\n",
    "you will get your X and y to use and train your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gkailasam\\AppData\\Local\\Continuum\\anaconda3_1\\lib\\site-packages\\pandas\\core\\indexing.py:494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "X, y = hr_prep.get_x_y_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PayRate</th>\n",
       "      <th>EngagementSurvey</th>\n",
       "      <th>EmpSatisfaction</th>\n",
       "      <th>SpecialProjectsCount</th>\n",
       "      <th>CurrentCmpyExp</th>\n",
       "      <th>DaysSinceLastRev</th>\n",
       "      <th>Age</th>\n",
       "      <th>EngagementSurvey_missing</th>\n",
       "      <th>EmpSatisfaction_missing</th>\n",
       "      <th>SpecialProjectsCount_missing</th>\n",
       "      <th>...</th>\n",
       "      <th>ManagerName_Jennifer Zamora</th>\n",
       "      <th>ManagerName_John Smith</th>\n",
       "      <th>ManagerName_Kelley Spirea</th>\n",
       "      <th>ManagerName_Ketsia Liebig</th>\n",
       "      <th>ManagerName_Kissy Sullivan</th>\n",
       "      <th>ManagerName_Lynn Daneault</th>\n",
       "      <th>ManagerName_Michael Albert</th>\n",
       "      <th>ManagerName_Peter Monroe</th>\n",
       "      <th>ManagerName_Simon Roup</th>\n",
       "      <th>ManagerName_Webster Butler</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.181317</td>\n",
       "      <td>-1.002786</td>\n",
       "      <td>-2.079060</td>\n",
       "      <td>2.039987</td>\n",
       "      <td>2.356114</td>\n",
       "      <td>0.784284</td>\n",
       "      <td>-0.953088</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.151994</td>\n",
       "      <td>-0.217479</td>\n",
       "      <td>-0.276385</td>\n",
       "      <td>-0.269563</td>\n",
       "      <td>-0.276385</td>\n",
       "      <td>-0.209215</td>\n",
       "      <td>-0.276385</td>\n",
       "      <td>-0.217479</td>\n",
       "      <td>-0.240874</td>\n",
       "      <td>-0.269563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.539418</td>\n",
       "      <td>1.294446</td>\n",
       "      <td>0.120628</td>\n",
       "      <td>1.188275</td>\n",
       "      <td>0.268304</td>\n",
       "      <td>0.773321</td>\n",
       "      <td>-0.614261</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.151994</td>\n",
       "      <td>-0.217479</td>\n",
       "      <td>-0.276385</td>\n",
       "      <td>-0.269563</td>\n",
       "      <td>-0.276385</td>\n",
       "      <td>-0.209215</td>\n",
       "      <td>-0.276385</td>\n",
       "      <td>-0.217479</td>\n",
       "      <td>-0.240874</td>\n",
       "      <td>-0.269563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.148762</td>\n",
       "      <td>0.440745</td>\n",
       "      <td>1.220472</td>\n",
       "      <td>1.614131</td>\n",
       "      <td>0.268304</td>\n",
       "      <td>0.767839</td>\n",
       "      <td>-0.840145</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.151994</td>\n",
       "      <td>-0.217479</td>\n",
       "      <td>-0.276385</td>\n",
       "      <td>-0.269563</td>\n",
       "      <td>-0.276385</td>\n",
       "      <td>-0.209215</td>\n",
       "      <td>-0.276385</td>\n",
       "      <td>-0.217479</td>\n",
       "      <td>-0.240874</td>\n",
       "      <td>-0.269563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.637082</td>\n",
       "      <td>-0.071476</td>\n",
       "      <td>-0.979216</td>\n",
       "      <td>1.188275</td>\n",
       "      <td>-1.764249</td>\n",
       "      <td>-1.413811</td>\n",
       "      <td>-0.727203</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.151994</td>\n",
       "      <td>-0.217479</td>\n",
       "      <td>-0.276385</td>\n",
       "      <td>-0.269563</td>\n",
       "      <td>-0.276385</td>\n",
       "      <td>-0.209215</td>\n",
       "      <td>-0.276385</td>\n",
       "      <td>-0.217479</td>\n",
       "      <td>-0.240874</td>\n",
       "      <td>-0.269563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.958722</td>\n",
       "      <td>1.294446</td>\n",
       "      <td>-0.979216</td>\n",
       "      <td>1.614131</td>\n",
       "      <td>-0.079664</td>\n",
       "      <td>0.784284</td>\n",
       "      <td>-1.066030</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.151994</td>\n",
       "      <td>-0.217479</td>\n",
       "      <td>-0.276385</td>\n",
       "      <td>-0.269563</td>\n",
       "      <td>-0.276385</td>\n",
       "      <td>-0.209215</td>\n",
       "      <td>-0.276385</td>\n",
       "      <td>-0.217479</td>\n",
       "      <td>-0.240874</td>\n",
       "      <td>-0.269563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>305</td>\n",
       "      <td>1.485482</td>\n",
       "      <td>-1.383071</td>\n",
       "      <td>1.220472</td>\n",
       "      <td>2.891699</td>\n",
       "      <td>0.268304</td>\n",
       "      <td>0.630801</td>\n",
       "      <td>2.999895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.151994</td>\n",
       "      <td>-0.217479</td>\n",
       "      <td>-0.276385</td>\n",
       "      <td>-0.269563</td>\n",
       "      <td>-0.276385</td>\n",
       "      <td>-0.209215</td>\n",
       "      <td>-0.276385</td>\n",
       "      <td>4.598136</td>\n",
       "      <td>-0.240874</td>\n",
       "      <td>-0.269563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>306</td>\n",
       "      <td>1.622211</td>\n",
       "      <td>0.875357</td>\n",
       "      <td>1.220472</td>\n",
       "      <td>2.039987</td>\n",
       "      <td>0.268304</td>\n",
       "      <td>0.828136</td>\n",
       "      <td>-0.840145</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.151994</td>\n",
       "      <td>-0.217479</td>\n",
       "      <td>-0.276385</td>\n",
       "      <td>-0.269563</td>\n",
       "      <td>-0.276385</td>\n",
       "      <td>-0.209215</td>\n",
       "      <td>-0.276385</td>\n",
       "      <td>4.598136</td>\n",
       "      <td>-0.240874</td>\n",
       "      <td>-0.269563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>307</td>\n",
       "      <td>1.465949</td>\n",
       "      <td>-0.048193</td>\n",
       "      <td>0.120628</td>\n",
       "      <td>1.614131</td>\n",
       "      <td>-0.427632</td>\n",
       "      <td>0.789765</td>\n",
       "      <td>-0.501318</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.151994</td>\n",
       "      <td>-0.217479</td>\n",
       "      <td>-0.276385</td>\n",
       "      <td>-0.269563</td>\n",
       "      <td>-0.276385</td>\n",
       "      <td>-0.209215</td>\n",
       "      <td>-0.276385</td>\n",
       "      <td>4.598136</td>\n",
       "      <td>-0.240874</td>\n",
       "      <td>-0.269563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>308</td>\n",
       "      <td>1.413862</td>\n",
       "      <td>1.294446</td>\n",
       "      <td>-0.979216</td>\n",
       "      <td>1.188275</td>\n",
       "      <td>0.268304</td>\n",
       "      <td>0.855544</td>\n",
       "      <td>1.531644</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.151994</td>\n",
       "      <td>-0.217479</td>\n",
       "      <td>-0.276385</td>\n",
       "      <td>-0.269563</td>\n",
       "      <td>-0.276385</td>\n",
       "      <td>-0.209215</td>\n",
       "      <td>-0.276385</td>\n",
       "      <td>4.598136</td>\n",
       "      <td>-0.240874</td>\n",
       "      <td>-0.269563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>309</td>\n",
       "      <td>1.557102</td>\n",
       "      <td>-1.763356</td>\n",
       "      <td>0.120628</td>\n",
       "      <td>2.891699</td>\n",
       "      <td>-0.079664</td>\n",
       "      <td>0.669172</td>\n",
       "      <td>0.063393</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.151994</td>\n",
       "      <td>-0.217479</td>\n",
       "      <td>-0.276385</td>\n",
       "      <td>-0.269563</td>\n",
       "      <td>-0.276385</td>\n",
       "      <td>-0.209215</td>\n",
       "      <td>-0.276385</td>\n",
       "      <td>4.598136</td>\n",
       "      <td>-0.240874</td>\n",
       "      <td>-0.269563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>310 rows × 149 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PayRate  EngagementSurvey  EmpSatisfaction  SpecialProjectsCount  \\\n",
       "0   -0.181317         -1.002786        -2.079060              2.039987   \n",
       "1   -0.539418          1.294446         0.120628              1.188275   \n",
       "2   -0.148762          0.440745         1.220472              1.614131   \n",
       "3   -0.637082         -0.071476        -0.979216              1.188275   \n",
       "4   -0.958722          1.294446        -0.979216              1.614131   \n",
       "..        ...               ...              ...                   ...   \n",
       "305  1.485482         -1.383071         1.220472              2.891699   \n",
       "306  1.622211          0.875357         1.220472              2.039987   \n",
       "307  1.465949         -0.048193         0.120628              1.614131   \n",
       "308  1.413862          1.294446        -0.979216              1.188275   \n",
       "309  1.557102         -1.763356         0.120628              2.891699   \n",
       "\n",
       "     CurrentCmpyExp  DaysSinceLastRev       Age  EngagementSurvey_missing  \\\n",
       "0          2.356114          0.784284 -0.953088                       0.0   \n",
       "1          0.268304          0.773321 -0.614261                       0.0   \n",
       "2          0.268304          0.767839 -0.840145                       0.0   \n",
       "3         -1.764249         -1.413811 -0.727203                       0.0   \n",
       "4         -0.079664          0.784284 -1.066030                       0.0   \n",
       "..              ...               ...       ...                       ...   \n",
       "305        0.268304          0.630801  2.999895                       0.0   \n",
       "306        0.268304          0.828136 -0.840145                       0.0   \n",
       "307       -0.427632          0.789765 -0.501318                       0.0   \n",
       "308        0.268304          0.855544  1.531644                       0.0   \n",
       "309       -0.079664          0.669172  0.063393                       0.0   \n",
       "\n",
       "     EmpSatisfaction_missing  SpecialProjectsCount_missing  ...  \\\n",
       "0                        0.0                           0.0  ...   \n",
       "1                        0.0                           0.0  ...   \n",
       "2                        0.0                           0.0  ...   \n",
       "3                        0.0                           0.0  ...   \n",
       "4                        0.0                           0.0  ...   \n",
       "..                       ...                           ...  ...   \n",
       "305                      0.0                           0.0  ...   \n",
       "306                      0.0                           0.0  ...   \n",
       "307                      0.0                           0.0  ...   \n",
       "308                      0.0                           0.0  ...   \n",
       "309                      0.0                           0.0  ...   \n",
       "\n",
       "     ManagerName_Jennifer Zamora  ManagerName_John Smith  \\\n",
       "0                      -0.151994               -0.217479   \n",
       "1                      -0.151994               -0.217479   \n",
       "2                      -0.151994               -0.217479   \n",
       "3                      -0.151994               -0.217479   \n",
       "4                      -0.151994               -0.217479   \n",
       "..                           ...                     ...   \n",
       "305                    -0.151994               -0.217479   \n",
       "306                    -0.151994               -0.217479   \n",
       "307                    -0.151994               -0.217479   \n",
       "308                    -0.151994               -0.217479   \n",
       "309                    -0.151994               -0.217479   \n",
       "\n",
       "     ManagerName_Kelley Spirea  ManagerName_Ketsia Liebig  \\\n",
       "0                    -0.276385                  -0.269563   \n",
       "1                    -0.276385                  -0.269563   \n",
       "2                    -0.276385                  -0.269563   \n",
       "3                    -0.276385                  -0.269563   \n",
       "4                    -0.276385                  -0.269563   \n",
       "..                         ...                        ...   \n",
       "305                  -0.276385                  -0.269563   \n",
       "306                  -0.276385                  -0.269563   \n",
       "307                  -0.276385                  -0.269563   \n",
       "308                  -0.276385                  -0.269563   \n",
       "309                  -0.276385                  -0.269563   \n",
       "\n",
       "     ManagerName_Kissy Sullivan  ManagerName_Lynn Daneault  \\\n",
       "0                     -0.276385                  -0.209215   \n",
       "1                     -0.276385                  -0.209215   \n",
       "2                     -0.276385                  -0.209215   \n",
       "3                     -0.276385                  -0.209215   \n",
       "4                     -0.276385                  -0.209215   \n",
       "..                          ...                        ...   \n",
       "305                   -0.276385                  -0.209215   \n",
       "306                   -0.276385                  -0.209215   \n",
       "307                   -0.276385                  -0.209215   \n",
       "308                   -0.276385                  -0.209215   \n",
       "309                   -0.276385                  -0.209215   \n",
       "\n",
       "     ManagerName_Michael Albert  ManagerName_Peter Monroe  \\\n",
       "0                     -0.276385                 -0.217479   \n",
       "1                     -0.276385                 -0.217479   \n",
       "2                     -0.276385                 -0.217479   \n",
       "3                     -0.276385                 -0.217479   \n",
       "4                     -0.276385                 -0.217479   \n",
       "..                          ...                       ...   \n",
       "305                   -0.276385                  4.598136   \n",
       "306                   -0.276385                  4.598136   \n",
       "307                   -0.276385                  4.598136   \n",
       "308                   -0.276385                  4.598136   \n",
       "309                   -0.276385                  4.598136   \n",
       "\n",
       "     ManagerName_Simon Roup  ManagerName_Webster Butler  \n",
       "0                 -0.240874                   -0.269563  \n",
       "1                 -0.240874                   -0.269563  \n",
       "2                 -0.240874                   -0.269563  \n",
       "3                 -0.240874                   -0.269563  \n",
       "4                 -0.240874                   -0.269563  \n",
       "..                      ...                         ...  \n",
       "305               -0.240874                   -0.269563  \n",
       "306               -0.240874                   -0.269563  \n",
       "307               -0.240874                   -0.269563  \n",
       "308               -0.240874                   -0.269563  \n",
       "309               -0.240874                   -0.269563  \n",
       "\n",
       "[310 rows x 149 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly_features = PolynomialFeatures(degree = 2, include_bias=False)\n",
    "# X_poly = poly_features.fit_transform(X)\n",
    "# X = X_poly\n",
    "# Unable to allocate 148. GiB for an array with shape (310, 64133474) and data type float64\n",
    "# Forcing polynomial features does not work because of burst in features 64133474"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For plotting learning curve\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_learning_curves(model, X, y):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
    "    y_train = y_train.to_numpy().reshape((len(y_train),))\n",
    "    y_val = y_val.to_numpy().reshape((len(y_val),))\n",
    "    train_errors, val_errors = [], []\n",
    "    for m in range(1, len(X_train)):\n",
    "        model.fit(X_train[:m], y_train[:m])\n",
    "        y_train_predict = model.predict(X_train[:m])\n",
    "        y_val_predict = model.predict(X_val)\n",
    "        train_errors.append(mean_squared_error(y_train[:m], y_train_predict))\n",
    "        val_errors.append(mean_squared_error(y_val, y_val_predict))\n",
    "    plt.plot(np.sqrt(train_errors), \"r-+\", linewidth=2, label=\"train\")\n",
    "    plt.plot(np.sqrt(val_errors), \"b-\", linewidth=3, label=\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#sss = StratifiedShuffleSplit(n_splits=5, test_size=0.3, random_state=0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "y_train = y_train.to_numpy().reshape((len(y_train),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "lreg = SGDRegressor(max_iter=1000, tol=1e-3, random_state=1)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(lreg, X_train, y_train, cv = 10, scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: -3.16 (+/- 3.03)\n"
     ]
    }
   ],
   "source": [
    "print(\"Score: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.29522796e+25, -2.80905227e+25, -1.25004638e+26, -6.68981858e+25,\n",
       "       -8.67586932e+26, -1.53002607e+26, -1.68366048e+26, -1.02082109e+26,\n",
       "       -1.52677723e+25, -2.85135336e+25])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "pipelines = []\n",
    "pipelines.append(('ScaledLR', Pipeline([('LR',LinearRegression())])))\n",
    "pipelines.append(('ScaledLASSO', Pipeline([('LASSO', Lasso())])))\n",
    "pipelines.append(('ScaledEN', Pipeline([('EN', ElasticNet())])))\n",
    "pipelines.append(('ScaledKNN', Pipeline([('KNN', KNeighborsRegressor())])))\n",
    "pipelines.append(('ScaledCART', Pipeline([('CART', DecisionTreeRegressor())])))\n",
    "pipelines.append(('ScaledGBM', Pipeline([('GBM', GradientBoostingRegressor())])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScaledLR: -0.477757 (0.138470)\n",
      "ScaledLASSO: -0.362863 (0.154623)\n",
      "ScaledEN: -0.362771 (0.153842)\n",
      "ScaledKNN: -0.372448 (0.156078)\n",
      "ScaledCART: -0.515714 (0.183254)\n",
      "ScaledGBM: -0.324329 (0.106307)\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "for name, model in pipelines:\n",
    "    kfold = KFold(n_splits=10, random_state=21)\n",
    "    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring='neg_mean_squared_error')\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gkailasam\\AppData\\Local\\Continuum\\anaconda3_1\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.273871 (0.104955) with: {'n_estimators': 8}\n",
      "-0.272147 (0.105793) with: {'n_estimators': 9}\n",
      "-0.275463 (0.110565) with: {'n_estimators': 10}\n",
      "-0.277931 (0.109855) with: {'n_estimators': 14}\n",
      "-0.277311 (0.107666) with: {'n_estimators': 15}\n",
      "-0.275964 (0.107831) with: {'n_estimators': 16}\n",
      "Best: -0.272147 using {'n_estimators': 9}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaledX = scaler.transform(X_train)\n",
    "param_grid = dict(n_estimators=np.array([8, 9, 10, 14, 15, 16]))\n",
    "model = GradientBoostingRegressor(random_state=21)\n",
    "kfold = KFold(n_splits=10, random_state=21)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='neg_mean_squared_error', cv=kfold)\n",
    "grid_result = grid.fit(rescaledX, y_train)\n",
    "\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_learning_curves(grid.best_estimator_, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = grid.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2604828430465249"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "scores = mean_squared_error(y_test, y_test_pred)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.156921 (1.491833) with: {'eta0': 0.015, 'max_iter': 1000}\n",
      "-3.115024 (1.461111) with: {'eta0': 0.015, 'max_iter': 1500}\n",
      "-3.128986 (1.457429) with: {'eta0': 0.015, 'max_iter': 2000}\n",
      "-3.075061 (1.563985) with: {'eta0': 0.016, 'max_iter': 1000}\n",
      "-3.108772 (1.442965) with: {'eta0': 0.016, 'max_iter': 1500}\n",
      "-3.243232 (1.729707) with: {'eta0': 0.016, 'max_iter': 2000}\n",
      "-3.495156 (1.758911) with: {'eta0': 0.017, 'max_iter': 1000}\n",
      "-3.590766 (2.108409) with: {'eta0': 0.017, 'max_iter': 1500}\n",
      "-4.060653 (2.243668) with: {'eta0': 0.017, 'max_iter': 2000}\n",
      "-4.043611 (1.951130) with: {'eta0': 0.018, 'max_iter': 1000}\n",
      "-4.942245 (2.484810) with: {'eta0': 0.018, 'max_iter': 1500}\n",
      "-3.877996 (1.576790) with: {'eta0': 0.018, 'max_iter': 2000}\n",
      "-5.642990 (3.720723) with: {'eta0': 0.019, 'max_iter': 1000}\n",
      "-6.201649 (2.781963) with: {'eta0': 0.019, 'max_iter': 1500}\n",
      "-6.118042 (4.560547) with: {'eta0': 0.019, 'max_iter': 2000}\n",
      "Best: -3.075061 using {'eta0': 0.016, 'max_iter': 1000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gkailasam\\AppData\\Local\\Continuum\\anaconda3_1\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "param_grid = {'eta0':(0.015, 0.016, 0.017, 0.018, 0.019), 'max_iter':[1000, 1500, 2000]}\n",
    "model = SGDRegressor(tol=1e-3)\n",
    "kfold = KFold(n_splits=10, random_state=21)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='neg_mean_squared_error', cv=kfold)\n",
    "\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
